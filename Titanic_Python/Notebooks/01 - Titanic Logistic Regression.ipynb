{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 0.1.0.1179783\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_history_name = \"BAS2018-train-titanic\"\n",
    "\n",
    "run = Run.start_logging(workspace = ws, history_name = run_history_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:0.7913486005089059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.restclient.metrics_client:Converting metric of <class 'numpy.ndarray'> to string, original type is unsupported\n",
      "WARNING:azureml.restclient.metrics_client:Converting metric of <class 'numpy.ndarray'> to string, original type is unsupported\n",
      "WARNING:azureml.restclient.metrics_client:Converting metric of <class 'numpy.ndarray'> to string, original type is unsupported\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classifiier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, roc_auc_score\n",
    "\n",
    "titanic_clean_df = pd.read_csv('C:\\\\dev\\Demos\\\\BAS2018\\\\Titanic_Python\\\\final_titanic_clean.csv')\n",
    "\n",
    "target_df = titanic_clean_df['survived']\n",
    "features_df = titanic_clean_df.drop(['survived', 'died'],axis=1)\n",
    "                                 \n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, target_df, test_size = 0.3, random_state=42)\n",
    "\n",
    "reg_rate = 10\n",
    "\n",
    "# Logistic Regression : \n",
    "# Fit the regressor to the training data\n",
    "lr = LogisticRegression(C=1/reg_rate).fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Score / Metrics\n",
    "lr_accuracy = lr.score(X_test, y_test)\n",
    "print('Accuracy is:' + str(lr_accuracy))\n",
    "\n",
    "run = Run.start_logging(workspace = ws, history_name = run_history_name)\n",
    "run.log('Accuracy', lr_accuracy)\n",
    "run.log('Regulization Rate', reg_rate)\n",
    "\n",
    "# calculate and log precesion, recall, and thresholds, which are list of numerical values\n",
    "y_scores = lr.predict_proba(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores[:,1])\n",
    "run.log(\"Precision\", precision)\n",
    "run.log(\"Recall\", recall)\n",
    "run.log(\"Thresholds\", thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.restclient.models.batch_artifact_content_information_dto.BatchArtifactContentInformationDto at 0x22657df3160>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(value = lr, filename = 'model.pkl');\n",
    "run.upload_file(name = 'outputs/model.pkl', path_or_stream = './model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mlworkspace.azureml-test.net/portal/subscriptions/35f16a99-532a-4a47-9e93-00305f6c40f2/resourceGroups/euangBASrg/providers/Microsoft.MachineLearningServices/workspaces/BAS2018_Titanic/history/BAS2018-train-titanic/runs/3c1e39b4-1ed6-4833-bcbf-245e35f959fb\n"
     ]
    }
   ],
   "source": [
    "import helpers\n",
    "print(helpers.get_run_history_url(run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.core.model.Model at 0x226579eb550>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.register_model(model_name = \"BestModel\", model_path = 'outputs/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Scoring Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # note here \"best_model\" is the name of the model registered under the workspace\n",
    "    # this call should return the path to the model.pkl file on the local disk.\n",
    "    model_path = Model.get_model_path(model_name = 'BestModel')\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = np.array(data)\n",
    "        result = model.predict(data)\n",
    "        return json.dumps({\"result\": result.tolist()})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dependencies File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting myenv.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile myenv.yml\n",
    "name: myenv\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - numpy\n",
    "    - scikit-learn\n",
    "    # Required packages for AzureML execution, history, and data preparation.\n",
    "    - --extra-index-url https://azuremlsdktestpypi.azureedge.net/sdk-release/Preview/E7501C02541B433786111FE8E140CAA1\n",
    "    - azureml-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = ['AML Titanic Logistic Regression'], \n",
    "                                               description = 'Our best effort at BAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this will take 5-10 minutes to finish\n",
    "# you can also use \"az container list\" command to find the ACI being deployed\n",
    "service = Webservice.deploy_from_model(name = 'live-aci-titanic',\n",
    "                                       deployment_config = aciconfig,\n",
    "                                       models = [model],\n",
    "                                       runtime = 'python',\n",
    "                                       conda_file = 'myenv.yml',\n",
    "                                       execution_script = 'score.py',\n",
    "                                       workspace = ws)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'service' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b7992f9373fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'web service is hosted in ACI:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring_uri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'service' is not defined"
     ]
    }
   ],
   "source": [
    "print('web service is hosted in ACI:', service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# score the first row from the test set.\n",
    "test_samples = json.dumps({\"data\": X_test[0:1, :].tolist()})\n",
    "service.run(input_data = test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shut Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amlsdk]",
   "language": "python",
   "name": "conda-env-amlsdk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
